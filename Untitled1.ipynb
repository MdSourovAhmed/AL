{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPxMNIW9iZyQbsRlDoeDpR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MdSourovAhmed/AL/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip3 install scapy paho-mqtt\n",
        "!python3 -c \"import sklearn; print('Scikit-Learn version:', sklearn.__version__)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tce3_gRhF-Cp",
        "outputId": "2745366e-bdd3-40d3-fd62-f59d12aebd66"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scikit-Learn version: 1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scapy.all import sniff, TCP, Raw, IP\n",
        "import sys\n",
        "\n",
        "# MQTT Port (default is 1883)\n",
        "MQTT_PORT = 1883\n",
        "\n",
        "# Callback function to process captured packets\n",
        "def process_packet(packet):\n",
        "    if packet.haslayer(TCP) and packet[TCP].dport == MQTT_PORT:\n",
        "        print(\"\\nTCP Packet Detected:\")\n",
        "        print(f\"Source IP: {packet[IP].src}\")\n",
        "        print(f\"Destination IP: {packet[IP].dst}\")\n",
        "        print(f\"Source Port: {packet[TCP].sport}\")\n",
        "        print(f\"Destination Port: {packet[TCP].dport}\")\n",
        "        print(f\"Packet Size: {len(packet)} bytes\")  # Packet size in bytes\n",
        "#       print(packet)\n",
        "        # Check if the packet contains raw data (payload)\n",
        "        if packet.haslayer(Raw):\n",
        "            payload = packet[Raw].load\n",
        "            print(\"Raw Payload (Hex):\", payload.hex())\n",
        "\n",
        "            # Attempt to decode the payload as a string (for debugging)\n",
        "            try:\n",
        "                payload_str = payload.decode(\"utf-8\", errors=\"ignore\")\n",
        "                print(\"Raw Payload (String):\", payload_str)\n",
        "            except Exception as e:\n",
        "                print(\"Error decoding payload:\", e)\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    try:\n",
        "        print(f\"Sniffing MQTT packets on port {MQTT_PORT}...\")\n",
        "        sniff(filter=f\"tcp port {MQTT_PORT}\", prn=process_packet, store=False)\n",
        "    except PermissionError:\n",
        "        print(\"Error: Permission denied. Please run the script as root or with sudo.\")\n",
        "        sys.exit(1)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nSniffing stopped by user.\")\n",
        "        sys.exit(0)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "HKkBRlBKNYrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from scapy.all import sniff, TCP, IP\n",
        "\n",
        "# Load the model and scaler\n",
        "model = joblib.load(\"intrusion_detection_model.pkl\")\n",
        "scaler = joblib.load(\"scaler.pkl\")\n",
        "MQTT_PORT=1883\n",
        "# Function to preprocess and predict\n",
        "def predict_intrusion(packet):\n",
        "    # Extract features from the packet (replace with actual feature extraction logic)\n",
        "    features = {\n",
        "        'Flow Duration': 1000,\n",
        "        'Total Fwd Packets': 10,\n",
        "        'Total Backward Packets': 5,\n",
        "        'Flow Bytes/s': 1000,\n",
        "        'Flow Packets/s': 10,\n",
        "        'Flow IAT Mean': 100,\n",
        "        'Flow IAT Std': 10,\n",
        "        'Fwd IAT Mean': 100,\n",
        "        'Bwd IAT Mean': 100,\n",
        "        'Fwd PSH Flags': 0,\n",
        "        'Bwd PSH Flags': 0,\n",
        "        'FIN Flag Count': 0,\n",
        "        'SYN Flag Count': 1,\n",
        "        'RST Flag Count': 0,\n",
        "        'ACK Flag Count': 1,\n",
        "        'Down/Up Ratio': 1.0,\n",
        "        'Average Packet Size': 100,\n",
        "        'Subflow Fwd Packets': 10,\n",
        "        'Subflow Bwd Packets': 5,\n",
        "        'Init_Win_bytes_forward': 65535,\n",
        "        'Init_Win_bytes_backward': 65535\n",
        "    }\n",
        "\n",
        "    # Convert features to DataFrame\n",
        "    features_df = pd.DataFrame([features])\n",
        "\n",
        "    # Normalize the features\n",
        "    features_scaled = scaler.transform(features_df)\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict(features_scaled)\n",
        "    return prediction[0]\n",
        "\n",
        "# Function to process MQTT packets\n",
        "def process_packet(packet):\n",
        "  if packet.haslayer(TCP) and packet[TCP].dport == MQTT_PORT:\n",
        "    prediction = predict_intrusion(packet)\n",
        "            if prediction == 1:  # Assuming 1 is the label for DDoS\n",
        "                print(\"DDoS attack detected!\")\n",
        "                send_email(\"DDoS attack detected on MQTT broker!\")\n",
        "        print(\"\\nTCP Packet Detected:\")\n",
        "        print(f\"Source IP: {packet[IP].src}\")\n",
        "        print(f\"Destination IP: {packet[IP].dst}\")\n",
        "        print(f\"Source Port: {packet[TCP].sport}\")\n",
        "        print(f\"Destination Port: {packet[TCP].dport}\")\n",
        "        print(f\"Packet Size: {len(packet)} bytes\")  # Packet size in bytes\n",
        "        print(packet)\n",
        "        # Check if the packet contains raw data (payload)\n",
        "        if packet.haslayer(Raw):\n",
        "            payload = packet[Raw].load\n",
        "            print(\"Raw Payload (Hex):\", payload.hex())\n",
        "\n",
        "            # Attempt to decode the payload as a string (for debugging)\n",
        "            try:\n",
        "                payload_str = payload.decode(\"utf-8\", errors=\"ignore\")\n",
        "                print(\"Raw Payload (String):\", payload_str)\n",
        "            except Exception as e:\n",
        "                print(\"Error decoding payload:\", e)\n",
        "    # if packet.haslayer(TCP) and packet.haslayer(IP):\n",
        "    #     # Check if the packet is MQTT (port 1883)\n",
        "    #     if packet[TCP].dport == 1883 or packet[TCP].sport == 1883:\n",
        "    #         # Predict intrusion\n",
        "            # prediction = predict_intrusion(packet)\n",
        "            # if prediction == 1:  # Assuming 1 is the label for DDoS\n",
        "            #     print(\"DDoS attack detected!\")\n",
        "            #     send_email(\"DDoS attack detected on MQTT broker!\")\n",
        "\n",
        "# Function to send email alerts\n",
        "def send_email(message):\n",
        "    # Use Gmail API or SendGrid to send email alerts\n",
        "    pass\n",
        "\n",
        "# Start sniffing MQTT packets\n",
        "# print(\"Starting packet capture...\")\n",
        "# sniff(filter=\"tcp port 1883\", prn=process_packet)\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    try:\n",
        "        print(f\"Sniffing MQTT packets on port {MQTT_PORT}...\")\n",
        "        sniff(filter=f\"tcp port {MQTT_PORT}\", prn=process_packet, store=False)\n",
        "    except PermissionError:\n",
        "        print(\"Error: Permission denied. Please run the script as root or with sudo.\")\n",
        "        sys.exit(1)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nSniffing stopped by user.\")\n",
        "        sys.exit(0)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "4v8lkXjGQq1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Load the CICIDS2017 dataset (modify with your file path)\n",
        "df = pd.read_csv('Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')\n",
        "\n",
        "# Fill missing values\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        "# Print the available columns to inspect the column names\n",
        "# print(df.columns)\n",
        "\n",
        "# Assuming the label column is named differently, for example, 'attack_cat'\n",
        "# Update the column name accordingly\n",
        "label_column = 'Label'  # Change this to the actual name of the label column in your dataset\n",
        "\n",
        "# Strip leading/trailing spaces from column names\n",
        "df.columns = df.columns.str.strip()\n",
        "# Filter for DDoS-related attacks (example of attack label filtering)\n",
        "#df = df[df[label_column].isin(['DDoS', 'BENIGN'])]\n",
        "\n",
        "y = df['Label']\n",
        "\n",
        "# Check unique values and their counts in the 'Label' column\n",
        "label_counts = df['Label'].value_counts()\n",
        "\n",
        "# Print the result\n",
        "print(label_counts)\n",
        "\n",
        "# print(y)"
      ],
      "metadata": {
        "id": "cdzaVLBADWJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")\n",
        "\n",
        "# Strip leading/trailing spaces from column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Verify the column names\n",
        "# print(\"Columns in the dataset:\", df.columns)\n",
        "\n",
        "# Check if the target column exists\n",
        "if 'Label' not in df.columns:\n",
        "    raise KeyError(\"The dataset does not contain a 'Label' column. Please check the dataset.\")\n",
        "\n",
        "# Encode the 'Label' column (if categorical)\n",
        "label_encoder = LabelEncoder()\n",
        "df['Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Separate features and labels\n",
        "X = df.drop(columns=['Label'])\n",
        "y = df['Label']\n",
        "\n",
        "relevant_features = [\n",
        "    'Flow Duration',\n",
        "    'Total Fwd Packets',\n",
        "    'Total Backward Packets',\n",
        "    'Flow Bytes/s',\n",
        "    'Flow Packets/s',\n",
        "    'Flow IAT Mean',\n",
        "    'Flow IAT Std',\n",
        "    'Fwd IAT Mean',\n",
        "    'Bwd IAT Mean',\n",
        "    'Fwd PSH Flags',\n",
        "    'Bwd PSH Flags',\n",
        "    'FIN Flag Count',\n",
        "    'SYN Flag Count',\n",
        "    'RST Flag Count',\n",
        "    'ACK Flag Count',\n",
        "    'Down/Up Ratio',\n",
        "    'Average Packet Size',\n",
        "    'Subflow Fwd Packets',\n",
        "    'Subflow Bwd Packets',\n",
        "    'Init_Win_bytes_forward',\n",
        "    'Init_Win_bytes_backward'\n",
        "]\n",
        "\n",
        "# Select the relevant columns\n",
        "X = df[relevant_features]\n",
        "\n",
        "# Normalize the features\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Impute or remove NaN values if necessary\n",
        "# For example, you can impute with the mean:\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "# Or you can remove rows with NaN values:\n",
        "# X.dropna(inplace=True)\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgvePOcTRn-t",
        "outputId": "dfaa8204-44e1-485b-bd69-fdfae097fb22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-661f2feccf03>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
            "<ipython-input-16-661f2feccf03>:60: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X.fillna(X.mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9999335533455891\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     19405\n",
            "           1       1.00      1.00      1.00     25744\n",
            "\n",
            "    accuracy                           1.00     45149\n",
            "   macro avg       1.00      1.00      1.00     45149\n",
            "weighted avg       1.00      1.00      1.00     45149\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier  # Lightweight model\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")\n",
        "\n",
        "# Strip leading/trailing spaces from column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Verify the column names\n",
        "print(\"Columns in the dataset:\", df.columns)\n",
        "\n",
        "# Check if the target column exists\n",
        "if 'Label' not in df.columns:\n",
        "    raise KeyError(\"The dataset does not contain a 'Label' column. Please check the dataset.\")\n",
        "\n",
        "# Encode the 'Label' column (if categorical)\n",
        "label_encoder = LabelEncoder()\n",
        "df['Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Select relevant features\n",
        "relevant_features = [\n",
        "    'Flow Duration',\n",
        "    'Total Fwd Packets',\n",
        "    'Total Backward Packets',\n",
        "    'Flow Bytes/s',\n",
        "    'Flow Packets/s',\n",
        "    'Flow IAT Mean',\n",
        "    'Flow IAT Std',\n",
        "    'Fwd IAT Mean',\n",
        "    'Bwd IAT Mean',\n",
        "    'Fwd PSH Flags',\n",
        "    'Bwd PSH Flags',\n",
        "    'FIN Flag Count',\n",
        "    'SYN Flag Count',\n",
        "    'RST Flag Count',\n",
        "    'ACK Flag Count',\n",
        "    'Down/Up Ratio',\n",
        "    'Average Packet Size',\n",
        "    'Subflow Fwd Packets',\n",
        "    'Subflow Bwd Packets',\n",
        "    'Init_Win_bytes_forward',\n",
        "    'Init_Win_bytes_backward'\n",
        "]\n",
        "\n",
        "# Select the relevant columns\n",
        "X = df[relevant_features]\n",
        "y = df['Label']\n",
        "\n",
        "# Handle infinite and NaN values\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a lightweight model (Decision Tree)\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Save the model and scaler for real-time use\n",
        "joblib.dump(model, \"intrusion_detection_model.pkl\")\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "print(\"Model and scaler saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "c0aCurXFYSJQ",
        "outputId": "9c6c7ddc-491f-437c-8b9d-16dc953db325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in the dataset: Index(['Destination Port', 'Flow Duration', 'Total Fwd Packets',\n",
            "       'Total Backward Packets', 'Total Length of Fwd Packets',\n",
            "       'Total Length of Bwd Packets', 'Fwd Packet Length Max',\n",
            "       'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
            "       'Fwd Packet Length Std', 'Bwd Packet Length Max',\n",
            "       'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n",
            "       'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s',\n",
            "       'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min',\n",
            "       'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max',\n",
            "       'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std',\n",
            "       'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags',\n",
            "       'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n",
            "       'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s',\n",
            "       'Min Packet Length', 'Max Packet Length', 'Packet Length Mean',\n",
            "       'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n",
            "       'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
            "       'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n",
            "       'Average Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n",
            "       'Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk',\n",
            "       'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk',\n",
            "       'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes',\n",
            "       'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
            "       'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n",
            "       'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
            "       'Idle Std', 'Idle Max', 'Idle Min', 'Label'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-798bd20cb156>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
            "<ipython-input-23-798bd20cb156>:57: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X.fillna(X.mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9999114044607854\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     19405\n",
            "           1       1.00      1.00      1.00     25744\n",
            "\n",
            "    accuracy                           1.00     45149\n",
            "   macro avg       1.00      1.00      1.00     45149\n",
            "weighted avg       1.00      1.00      1.00     45149\n",
            "\n",
            "Model and scaler saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Import classifiers\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")\n",
        "\n",
        "# Strip leading/trailing spaces from column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Verify the column names\n",
        "# print(\"Columns in the dataset:\", df.columns)\n",
        "\n",
        "# Check if the target column exists\n",
        "if 'Label' not in df.columns:\n",
        "    raise KeyError(\"The dataset does not contain a 'Label' column. Please check the dataset.\")\n",
        "\n",
        "# Encode the 'Label' column (if categorical)\n",
        "label_encoder = LabelEncoder()\n",
        "df['Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Select relevant features\n",
        "relevant_features = [\n",
        "    'Flow Duration',\n",
        "    'Total Fwd Packets',\n",
        "    'Total Backward Packets',\n",
        "    'Flow Bytes/s',\n",
        "    'Flow Packets/s',\n",
        "    'Flow IAT Mean',\n",
        "    'Flow IAT Std',\n",
        "    'Fwd IAT Mean',\n",
        "    'Bwd IAT Mean',\n",
        "    'Fwd PSH Flags',\n",
        "    'Bwd PSH Flags',\n",
        "    'FIN Flag Count',\n",
        "    'SYN Flag Count',\n",
        "    'RST Flag Count',\n",
        "    'ACK Flag Count',\n",
        "    'Down/Up Ratio',\n",
        "    'Average Packet Size',\n",
        "    'Subflow Fwd Packets',\n",
        "    'Subflow Bwd Packets',\n",
        "    'Init_Win_bytes_forward',\n",
        "    'Init_Win_bytes_backward'\n",
        "]\n",
        "\n",
        "# Select the relevant columns\n",
        "X = df[relevant_features]\n",
        "y = df['Label']\n",
        "\n",
        "# Handle infinite and NaN values\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define classifiers to compare\n",
        "classifiers = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"Support Vector Machine\": SVC(kernel='linear', random_state=42),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5)\n",
        "}\n",
        "\n",
        "# Train and evaluate each classifier\n",
        "results = {}\n",
        "for name, clf in classifiers.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    # Store results\n",
        "    results[name] = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"classification_report\": report\n",
        "    }\n",
        "\n",
        "    # Print results\n",
        "    print(f\"{name} Results:\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Classification Report:\\n{report}\\n\")\n",
        "\n",
        "# Save the best model (e.g., Random Forest)\n",
        "best_model = classifiers[\"Decision Tree\"]\n",
        "joblib.dump(best_model, \"intrusion_detection_model.pkl\")\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "print(\"Best model (Decision Tree) and scaler saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0cPjhQpbNQD",
        "outputId": "ea9ac8a5-aa8f-4779-e22e-5b80a700b148"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-53e4c1825841>:62: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
            "<ipython-input-3-53e4c1825841>:63: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X.fillna(X.mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Decision Tree...\n",
            "Decision Tree Results:\n",
            "Accuracy: 0.9999114044607854\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     19405\n",
            "           1       1.00      1.00      1.00     25744\n",
            "\n",
            "    accuracy                           1.00     45149\n",
            "   macro avg       1.00      1.00      1.00     45149\n",
            "weighted avg       1.00      1.00      1.00     45149\n",
            "\n",
            "\n",
            "Training Random Forest...\n",
            "Random Forest Results:\n",
            "Accuracy: 0.9999335533455891\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     19405\n",
            "           1       1.00      1.00      1.00     25744\n",
            "\n",
            "    accuracy                           1.00     45149\n",
            "   macro avg       1.00      1.00      1.00     45149\n",
            "weighted avg       1.00      1.00      1.00     45149\n",
            "\n",
            "\n",
            "Training Gradient Boosting...\n",
            "Gradient Boosting Results:\n",
            "Accuracy: 0.9997120644975526\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     19405\n",
            "           1       1.00      1.00      1.00     25744\n",
            "\n",
            "    accuracy                           1.00     45149\n",
            "   macro avg       1.00      1.00      1.00     45149\n",
            "weighted avg       1.00      1.00      1.00     45149\n",
            "\n",
            "\n",
            "Training Logistic Regression...\n",
            "Logistic Regression Results:\n",
            "Accuracy: 0.954107510686837\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.95     19405\n",
            "           1       0.95      0.97      0.96     25744\n",
            "\n",
            "    accuracy                           0.95     45149\n",
            "   macro avg       0.96      0.95      0.95     45149\n",
            "weighted avg       0.95      0.95      0.95     45149\n",
            "\n",
            "\n",
            "Training Support Vector Machine...\n",
            "Support Vector Machine Results:\n",
            "Accuracy: 0.9581164588362976\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.93      0.95     19405\n",
            "           1       0.95      0.98      0.96     25744\n",
            "\n",
            "    accuracy                           0.96     45149\n",
            "   macro avg       0.96      0.95      0.96     45149\n",
            "weighted avg       0.96      0.96      0.96     45149\n",
            "\n",
            "\n",
            "Training K-Nearest Neighbors...\n",
            "K-Nearest Neighbors Results:\n",
            "Accuracy: 0.9994241289951051\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     19405\n",
            "           1       1.00      1.00      1.00     25744\n",
            "\n",
            "    accuracy                           1.00     45149\n",
            "   macro avg       1.00      1.00      1.00     45149\n",
            "weighted avg       1.00      1.00      1.00     45149\n",
            "\n",
            "\n",
            "Best model (Random Forest) and scaler saved.\n"
          ]
        }
      ]
    }
  ]
}